Mean:
F0        82.669758
F1       126.453971
F2        83.662616
F3        85.599579
x          7.500000
y          7.436842
Fdist    311.351552
Sx        -0.157280
Sy         0.038515
Name: mean, dtype: float64
Std:
F0       106.510489
F1       204.268260
F2       128.503499
F3       149.708490
x          5.164159
y          5.236644
Fdist    179.464143
Sx        45.116143
Sy         9.908787
Name: std, dtype: float64

dataTrain, dataTest = train_test_split(datasFull, test_size=0.15)
dataTrain, dataVal = train_test_split(dataTrain, test_size=0.2)

def build_model():
    # Define model layers.
    input_layer = layers.Input(shape=(len(norm_train_X[1]),))
    x = layers.Dense(130)(input_layer)   
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)
    
    x = layers.Dense(130)(x)   
    #x = layers.LSTM(128,input_shape=(1, 130))(x)   
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)    
    
    x = layers.Dense(130)(x)  
    #x = layers.LSTM(130)(x)
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)  
    
    x = layers.Dense(130)(x)   
    #x = layers.LSTM(130)(x)
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)    
    
    third_dense = layers.Dense(units='130', activation='relu')(x)
    #third_dense = layers.LSTM(units='130', activation='relu')(x)
    #third_dense=layers.Dropout(0.5)(third_dense)
    
    # Y1 output will be fed from the first dense
    y1_output = layers.Dense(units='1', name='x_output')(third_dense)
    
    # Y2 output will be fed from the second dense
    y2_output = layers.Dense(units='1', name='y_output')(third_dense)

    # Define the model with the input layer and a list of output layers
    model = Model(inputs=input_layer, outputs=[y1_output, y2_output])

    return model

# Train the model for 200 epochs
history = model.fit(norm_train_X, train_Y,
                    epochs=10000,batch_size=1100, verbose=2, validation_data=(norm_test_X, test_Y), use_multiprocessing=True)

1262/1262 [==============================] - 5s 4ms/step - loss: 0.2199 - x_output_loss: 0.1680 - y_output_loss: 0.0519 - x_output_root_mean_squared_error: 0.4098 - y_output_root_mean_squared_error: 0.2279A: 2s - loss: 0.1997 - x_output_loss: 0.1538 - y_output_loss: 0.0459 - x_output_root_mean_squared_error: 0.3921 

loss: 0.2198733240365982
x_loss: 0.16795702278614044
y_loss: 0.051916323602199554
x_rmse: 0.4098255932331085
y_rmse: 0.22785153985023499