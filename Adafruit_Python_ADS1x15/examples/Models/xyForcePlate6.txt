Mean: F0    385.350284
F1    132.483951
F2    366.454000
F3    355.273467
x       7.500000
y       7.500000
Name: mean, dtype: float64
Std: F0    109.484312
F1    185.298980
F2    176.520386
F3    201.882096
x       6.123792
y       6.123792

dataTrain, dataTest = train_test_split(datasFull, test_size=0.1)
dataTrain, dataVal = train_test_split(dataTrain, test_size=0.2)

def build_model():
    # Define model layers.
    input_layer = layers.Input(shape=(len(norm_train_X[1]),))
    x = layers.Dense(130)(input_layer)   
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)
    
    x = layers.Dense(130)(x)   
    x = layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)
    
    #x = layers.Dense(70)(x)
    #x = layers.BatchNormalization()(x)
    #x = tf.keras.activations.relu(x)
    
    third_dense = layers.Dense(units='130', activation='relu')(x)
    #third_dense=layers.Dropout(0.5)(third_dense)
    
    # Y1 output will be fed from the first dense
    y1_output = layers.Dense(units='1', name='x_output')(third_dense)
    
    # Y2 output will be fed from the second dense
    y2_output = layers.Dense(units='1', name='y_output')(third_dense)

    # Define the model with the input layer and a list of output layers
    model = Model(inputs=input_layer, outputs=[y1_output, y2_output])

    return model

model = build_model()

# Specify the optimizer, and compile the model with loss functions for both outputs
optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)
model.compile(optimizer=optimizer,
              loss={'x_output': 'mse', 'y_output': 'mse'},
              metrics={'x_output': tf.keras.metrics.RootMeanSquaredError(),
                       'y_output': tf.keras.metrics.RootMeanSquaredError()})

# Train the model for 200 epochs
history = model.fit(norm_train_X, train_Y,
                    epochs=300, validation_data=(norm_test_X, test_Y))

254/254 [==============================] - 2s 6ms/step - loss: 0.0728 - x_output_loss: 0.0226 - y_output_loss: 0.0502 - x_output_root_mean_squared_error: 0.1505 - y_output_root_mean_squared_error: 0.2240

loss: 0.07282107323408127
x_loss: 0.022636855021119118
y_loss: 0.0501842238008976
x_rmse: 0.15045548975467682
y_rmse: 0.22401835024356842